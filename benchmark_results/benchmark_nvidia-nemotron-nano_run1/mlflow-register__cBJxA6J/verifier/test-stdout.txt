Get:1 http://deb.debian.org/debian bookworm InRelease [151 kB]
Get:2 http://deb.debian.org/debian bookworm-updates InRelease [55.4 kB]
Get:3 http://deb.debian.org/debian-security bookworm-security InRelease [48.0 kB]
Get:4 http://deb.debian.org/debian bookworm/main amd64 Packages [8791 kB]
Get:5 http://deb.debian.org/debian bookworm-updates/main amd64 Packages [6924 B]
Get:6 http://deb.debian.org/debian-security bookworm-security/main amd64 Packages [290 kB]
Fetched 9342 kB in 3s (2670 kB/s)
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
The following additional packages will be installed:
  krb5-locales libbrotli1 libcurl4 libgssapi-krb5-2 libk5crypto3 libkeyutils1
  libkrb5-3 libkrb5support0 libldap-2.5-0 libldap-common libnghttp2-14 libpsl5
  librtmp1 libsasl2-2 libsasl2-modules libsasl2-modules-db libssh2-1
  publicsuffix
Suggested packages:
  krb5-doc krb5-user libsasl2-modules-gssapi-mit
  | libsasl2-modules-gssapi-heimdal libsasl2-modules-ldap libsasl2-modules-otp
  libsasl2-modules-sql
The following NEW packages will be installed:
  curl krb5-locales libbrotli1 libcurl4 libgssapi-krb5-2 libk5crypto3
  libkeyutils1 libkrb5-3 libkrb5support0 libldap-2.5-0 libldap-common
  libnghttp2-14 libpsl5 librtmp1 libsasl2-2 libsasl2-modules
  libsasl2-modules-db libssh2-1 publicsuffix
0 upgraded, 19 newly installed, 0 to remove and 0 not upgraded.
Need to get 2493 kB of archives.
After this operation, 6813 kB of additional disk space will be used.
Get:1 http://deb.debian.org/debian bookworm/main amd64 krb5-locales all 1.20.1-2+deb12u4 [63.4 kB]
Get:2 http://deb.debian.org/debian bookworm/main amd64 libbrotli1 amd64 1.0.9-2+b6 [275 kB]
Get:3 http://deb.debian.org/debian bookworm/main amd64 libkrb5support0 amd64 1.20.1-2+deb12u4 [33.2 kB]
Get:4 http://deb.debian.org/debian bookworm/main amd64 libk5crypto3 amd64 1.20.1-2+deb12u4 [79.8 kB]
Get:5 http://deb.debian.org/debian bookworm/main amd64 libkeyutils1 amd64 1.6.3-2 [8808 B]
Get:6 http://deb.debian.org/debian bookworm/main amd64 libkrb5-3 amd64 1.20.1-2+deb12u4 [334 kB]
Get:7 http://deb.debian.org/debian bookworm/main amd64 libgssapi-krb5-2 amd64 1.20.1-2+deb12u4 [135 kB]
Get:8 http://deb.debian.org/debian bookworm/main amd64 libsasl2-modules-db amd64 2.1.28+dfsg-10 [20.3 kB]
Get:9 http://deb.debian.org/debian bookworm/main amd64 libsasl2-2 amd64 2.1.28+dfsg-10 [59.7 kB]
Get:10 http://deb.debian.org/debian bookworm/main amd64 libldap-2.5-0 amd64 2.5.13+dfsg-5 [183 kB]
Get:11 http://deb.debian.org/debian bookworm/main amd64 libnghttp2-14 amd64 1.52.0-1+deb12u2 [73.0 kB]
Get:12 http://deb.debian.org/debian bookworm/main amd64 libpsl5 amd64 0.21.2-1 [58.7 kB]
Get:13 http://deb.debian.org/debian bookworm/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-2+b2 [60.8 kB]
Get:14 http://deb.debian.org/debian bookworm/main amd64 libssh2-1 amd64 1.10.0-3+b1 [179 kB]
Get:15 http://deb.debian.org/debian bookworm/main amd64 libcurl4 amd64 7.88.1-10+deb12u14 [392 kB]
Get:16 http://deb.debian.org/debian bookworm/main amd64 curl amd64 7.88.1-10+deb12u14 [316 kB]
Get:17 http://deb.debian.org/debian bookworm/main amd64 libldap-common all 2.5.13+dfsg-5 [29.3 kB]
Get:18 http://deb.debian.org/debian bookworm/main amd64 libsasl2-modules amd64 2.1.28+dfsg-10 [66.6 kB]
Get:19 http://deb.debian.org/debian bookworm/main amd64 publicsuffix all 20230209.2326-1 [126 kB]
Fetched 2493 kB in 0s (33.4 MB/s)
Selecting previously unselected package krb5-locales.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 6638 files and directories currently installed.)
Preparing to unpack .../00-krb5-locales_1.20.1-2+deb12u4_all.deb ...
Unpacking krb5-locales (1.20.1-2+deb12u4) ...
Selecting previously unselected package libbrotli1:amd64.
Preparing to unpack .../01-libbrotli1_1.0.9-2+b6_amd64.deb ...
Unpacking libbrotli1:amd64 (1.0.9-2+b6) ...
Selecting previously unselected package libkrb5support0:amd64.
Preparing to unpack .../02-libkrb5support0_1.20.1-2+deb12u4_amd64.deb ...
Unpacking libkrb5support0:amd64 (1.20.1-2+deb12u4) ...
Selecting previously unselected package libk5crypto3:amd64.
Preparing to unpack .../03-libk5crypto3_1.20.1-2+deb12u4_amd64.deb ...
Unpacking libk5crypto3:amd64 (1.20.1-2+deb12u4) ...
Selecting previously unselected package libkeyutils1:amd64.
Preparing to unpack .../04-libkeyutils1_1.6.3-2_amd64.deb ...
Unpacking libkeyutils1:amd64 (1.6.3-2) ...
Selecting previously unselected package libkrb5-3:amd64.
Preparing to unpack .../05-libkrb5-3_1.20.1-2+deb12u4_amd64.deb ...
Unpacking libkrb5-3:amd64 (1.20.1-2+deb12u4) ...
Selecting previously unselected package libgssapi-krb5-2:amd64.
Preparing to unpack .../06-libgssapi-krb5-2_1.20.1-2+deb12u4_amd64.deb ...
Unpacking libgssapi-krb5-2:amd64 (1.20.1-2+deb12u4) ...
Selecting previously unselected package libsasl2-modules-db:amd64.
Preparing to unpack .../07-libsasl2-modules-db_2.1.28+dfsg-10_amd64.deb ...
Unpacking libsasl2-modules-db:amd64 (2.1.28+dfsg-10) ...
Selecting previously unselected package libsasl2-2:amd64.
Preparing to unpack .../08-libsasl2-2_2.1.28+dfsg-10_amd64.deb ...
Unpacking libsasl2-2:amd64 (2.1.28+dfsg-10) ...
Selecting previously unselected package libldap-2.5-0:amd64.
Preparing to unpack .../09-libldap-2.5-0_2.5.13+dfsg-5_amd64.deb ...
Unpacking libldap-2.5-0:amd64 (2.5.13+dfsg-5) ...
Selecting previously unselected package libnghttp2-14:amd64.
Preparing to unpack .../10-libnghttp2-14_1.52.0-1+deb12u2_amd64.deb ...
Unpacking libnghttp2-14:amd64 (1.52.0-1+deb12u2) ...
Selecting previously unselected package libpsl5:amd64.
Preparing to unpack .../11-libpsl5_0.21.2-1_amd64.deb ...
Unpacking libpsl5:amd64 (0.21.2-1) ...
Selecting previously unselected package librtmp1:amd64.
Preparing to unpack .../12-librtmp1_2.4+20151223.gitfa8646d.1-2+b2_amd64.deb ...
Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2+b2) ...
Selecting previously unselected package libssh2-1:amd64.
Preparing to unpack .../13-libssh2-1_1.10.0-3+b1_amd64.deb ...
Unpacking libssh2-1:amd64 (1.10.0-3+b1) ...
Selecting previously unselected package libcurl4:amd64.
Preparing to unpack .../14-libcurl4_7.88.1-10+deb12u14_amd64.deb ...
Unpacking libcurl4:amd64 (7.88.1-10+deb12u14) ...
Selecting previously unselected package curl.
Preparing to unpack .../15-curl_7.88.1-10+deb12u14_amd64.deb ...
Unpacking curl (7.88.1-10+deb12u14) ...
Selecting previously unselected package libldap-common.
Preparing to unpack .../16-libldap-common_2.5.13+dfsg-5_all.deb ...
Unpacking libldap-common (2.5.13+dfsg-5) ...
Selecting previously unselected package libsasl2-modules:amd64.
Preparing to unpack .../17-libsasl2-modules_2.1.28+dfsg-10_amd64.deb ...
Unpacking libsasl2-modules:amd64 (2.1.28+dfsg-10) ...
Selecting previously unselected package publicsuffix.
Preparing to unpack .../18-publicsuffix_20230209.2326-1_all.deb ...
Unpacking publicsuffix (20230209.2326-1) ...
Setting up libkeyutils1:amd64 (1.6.3-2) ...
Setting up libpsl5:amd64 (0.21.2-1) ...
Setting up libbrotli1:amd64 (1.0.9-2+b6) ...
Setting up libsasl2-modules:amd64 (2.1.28+dfsg-10) ...
Setting up libnghttp2-14:amd64 (1.52.0-1+deb12u2) ...
Setting up krb5-locales (1.20.1-2+deb12u4) ...
Setting up libldap-common (2.5.13+dfsg-5) ...
Setting up libkrb5support0:amd64 (1.20.1-2+deb12u4) ...
Setting up libsasl2-modules-db:amd64 (2.1.28+dfsg-10) ...
Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2+b2) ...
Setting up libk5crypto3:amd64 (1.20.1-2+deb12u4) ...
Setting up libsasl2-2:amd64 (2.1.28+dfsg-10) ...
Setting up libssh2-1:amd64 (1.10.0-3+b1) ...
Setting up libkrb5-3:amd64 (1.20.1-2+deb12u4) ...
Setting up publicsuffix (20230209.2326-1) ...
Setting up libldap-2.5-0:amd64 (2.5.13+dfsg-5) ...
Setting up libgssapi-krb5-2:amd64 (1.20.1-2+deb12u4) ...
Setting up libcurl4:amd64 (7.88.1-10+deb12u14) ...
Setting up curl (7.88.1-10+deb12u14) ...
Processing triggers for libc-bin (2.36-9+deb12u13) ...
no checksums to verify
installing to /root/.local/bin
  uv
  uvx
everything's installed!

To add $HOME/.local/bin to your PATH, either restart your shell or run:

    source $HOME/.local/bin/env (sh, bash, zsh)
    source $HOME/.local/bin/env.fish (fish)
============================= test session starts ==============================
platform linux -- Python 3.13.11, pytest-8.4.1, pluggy-1.6.0
rootdir: /tests
plugins: anyio-4.12.0
collected 3 items

../tests/test_outputs.py FFF                                             [100%]

=================================== FAILURES ===================================
__________________________ test_mlflow_server_running __________________________

self = <HTTPConnection(host='localhost', port=8080) at 0x756a63a4cc20>

    def _new_conn(self) -> socket.socket:
        """Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        try:
>           sock = connection.create_connection(
                (self._dns_host, self.port),
                self.timeout,
                source_address=self.source_address,
                socket_options=self.socket_options,
            )

.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:204: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/urllib3/util/connection.py:85: in create_connection
    raise err
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 8080), timeout = None, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address: tuple[str, int],
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        source_address: tuple[str, int] | None = None,
        socket_options: _TYPE_SOCKET_OPTIONS | None = None,
    ) -> socket.socket:
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`socket.getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        try:
            host.encode("idna")
        except UnicodeError:
            raise LocationParseError(f"'{host}', label empty or too long") from None
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not _DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

.tbench-testing/lib/python3.13/site-packages/urllib3/util/connection.py:73: ConnectionRefusedError

The above exception was the direct cause of the following exception:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x756a63a4c830>
method = 'GET', url = '/', body = None
headers = {'User-Agent': 'python-requests/2.32.5', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None
release_conn = False, chunked = False, body_pos = None, preload_content = False
decode_content = False, response_kw = {}
parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/', query=None, fragment=None)
destination_scheme = None, conn = None, release_this_conn = True
http_tunnel_required = False, err = None, clean_exit = False

    def urlopen(  # type: ignore[override]
        self,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | bool | int | None = None,
        redirect: bool = True,
        assert_same_host: bool = True,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        pool_timeout: int | None = None,
        release_conn: bool | None = None,
        chunked: bool = False,
        body_pos: _TYPE_BODY_POSITION | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        **response_kw: typing.Any,
    ) -> BaseHTTPResponse:
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method
           such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param url:
            The URL to perform the request on.
    
        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param bool preload_content:
            If True, the response's body will be preloaded into memory.
    
        :param bool decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of ``preload_content``
            which defaults to ``True``.
    
        :param bool chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
        """
        parsed_url = parse_url(url)
        destination_scheme = parsed_url.scheme
    
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = preload_content
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = to_str(_encode_target(url))
        else:
            url = to_str(parsed_url.url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        http_tunnel_required = connection_requires_http_tunnel(
            self.proxy, self.proxy_config, destination_scheme
        )
    
        # Merge the proxy headers. Only done when not using HTTP CONNECT. We
        # have to copy the headers dict so we can safely change it without those
        # changes being reflected in anyone else's copy.
        if not http_tunnel_required:
            headers = headers.copy()  # type: ignore[attr-defined]
            headers.update(self.proxy_headers)  # type: ignore[union-attr]
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]
    
            # Is this a closed/new connection that requires CONNECT tunnelling?
            if self.proxy is not None and http_tunnel_required and conn.is_closed:
                try:
                    self._prepare_proxy(conn)
                except (BaseSSLError, OSError, SocketTimeout) as e:
                    self._raise_timeout(
                        err=e, url=self.proxy.url, timeout_value=conn.timeout
                    )
                    raise
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Make the request on the HTTPConnection object
>           response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
                retries=retries,
                response_conn=response_conn,
                preload_content=preload_content,
                decode_content=decode_content,
                **response_kw,
            )

.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:493: in _make_request
    conn.request(
.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:500: in request
    self.endheaders()
/usr/local/lib/python3.13/http/client.py:1353: in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
/usr/local/lib/python3.13/http/client.py:1113: in _send_output
    self.send(msg)
/usr/local/lib/python3.13/http/client.py:1057: in send
    self.connect()
.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:331: in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <HTTPConnection(host='localhost', port=8080) at 0x756a63a4cc20>

    def _new_conn(self) -> socket.socket:
        """Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        try:
            sock = connection.create_connection(
                (self._dns_host, self.port),
                self.timeout,
                source_address=self.source_address,
                socket_options=self.socket_options,
            )
        except socket.gaierror as e:
            raise NameResolutionError(self.host, self, e) from e
        except SocketTimeout as e:
            raise ConnectTimeoutError(
                self,
                f"Connection to {self.host} timed out. (connect timeout={self.timeout})",
            ) from e
    
        except OSError as e:
>           raise NewConnectionError(
                self, f"Failed to establish a new connection: {e}"
            ) from e
E           urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused

.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:219: NewConnectionError

The above exception was the direct cause of the following exception:

self = <requests.adapters.HTTPAdapter object at 0x756a6457ec60>
request = <PreparedRequest [GET]>, stream = False
timeout = Timeout(connect=None, read=None, total=None), verify = True
cert = None, proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )
    
        chunked = not (request.body is None or "Content-Length" in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, "
                    f"or a single float to set both timeouts to the same value."
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
>           resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )

.tbench-testing/lib/python3.13/site-packages/requests/adapters.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:841: in urlopen
    retries = retries.increment(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=None, read=False, redirect=None, status=None)
method = 'GET', url = '/', response = None
error = NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x756a63a4c830>
_stacktrace = <traceback object at 0x756a64569680>

    def increment(
        self,
        method: str | None = None,
        url: str | None = None,
        response: BaseHTTPResponse | None = None,
        error: Exception | None = None,
        _pool: ConnectionPool | None = None,
        _stacktrace: TracebackType | None = None,
    ) -> Self:
        """Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.BaseHTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        other = self.other
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or method is None or not self._is_method_retryable(method):
                raise reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif error:
            # Other retry?
            if other is not None:
                other -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            response_redirect_location = response.get_redirect_location()
            if response_redirect_location:
                redirect_location = response_redirect_location
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and the given method is in the allowed_methods
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            other=other,
            history=history,
        )
    
        if new_retry.is_exhausted():
            reason = error or ResponseError(cause)
>           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: / (Caused by NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused"))

.tbench-testing/lib/python3.13/site-packages/urllib3/util/retry.py:519: MaxRetryError

During handling of the above exception, another exception occurred:

    def test_mlflow_server_running():
        """Ensure the MLflow server is running."""
        try:
>           response = requests.get("http://localhost:8080")
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:12: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/requests/api.py:73: in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/requests/api.py:59: in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/requests/sessions.py:589: in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/requests/sessions.py:703: in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x756a6457ec60>
request = <PreparedRequest [GET]>, stream = False
timeout = Timeout(connect=None, read=None, total=None), verify = True
cert = None, proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )
    
        chunked = not (request.body is None or "Content-Length" in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, "
                    f"or a single float to set both timeouts to the same value."
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )
    
        except (ProtocolError, OSError) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: / (Caused by NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused"))

.tbench-testing/lib/python3.13/site-packages/requests/adapters.py:677: ConnectionError

During handling of the above exception, another exception occurred:

    def test_mlflow_server_running():
        """Ensure the MLflow server is running."""
        try:
            response = requests.get("http://localhost:8080")
            assert response.status_code == 200, "MLflow server is not running"
        except requests.exceptions.ConnectionError:
>           assert False, "Could not connect to MLflow server"
E           AssertionError: Could not connect to MLflow server
E           assert False

/tests/test_outputs.py:15: AssertionError
____________________________ test_model_registered _____________________________

self = <HTTPConnection(host='localhost', port=8080) at 0x756a63359150>

    def _new_conn(self) -> socket.socket:
        """Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        try:
>           sock = connection.create_connection(
                (self._dns_host, self.port),
                self.timeout,
                source_address=self.source_address,
                socket_options=self.socket_options,
            )

.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:204: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/urllib3/util/connection.py:85: in create_connection
    raise err
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 8080), timeout = 120, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address: tuple[str, int],
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        source_address: tuple[str, int] | None = None,
        socket_options: _TYPE_SOCKET_OPTIONS | None = None,
    ) -> socket.socket:
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`socket.getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        try:
            host.encode("idna")
        except UnicodeError:
            raise LocationParseError(f"'{host}', label empty or too long") from None
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not _DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

.tbench-testing/lib/python3.13/site-packages/urllib3/util/connection.py:73: ConnectionRefusedError

The above exception was the direct cause of the following exception:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x756a63ffb4d0>
method = 'GET'
url = '/api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100'
body = None
headers = {'User-Agent': 'mlflow-python-client/2.22.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}
retries = Retry(total=0, connect=0, read=7, redirect=7, status=7)
redirect = False, assert_same_host = False
timeout = Timeout(connect=120, read=120, total=None), pool_timeout = None
release_conn = False, chunked = False, body_pos = None, preload_content = False
decode_content = False, response_kw = {}
parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/api/2.0/mlflow/registered-models/search', query='filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100', fragment=None)
destination_scheme = None, conn = None, release_this_conn = True
http_tunnel_required = False, err = None, clean_exit = False

    def urlopen(  # type: ignore[override]
        self,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | bool | int | None = None,
        redirect: bool = True,
        assert_same_host: bool = True,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        pool_timeout: int | None = None,
        release_conn: bool | None = None,
        chunked: bool = False,
        body_pos: _TYPE_BODY_POSITION | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        **response_kw: typing.Any,
    ) -> BaseHTTPResponse:
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method
           such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param url:
            The URL to perform the request on.
    
        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param bool preload_content:
            If True, the response's body will be preloaded into memory.
    
        :param bool decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of ``preload_content``
            which defaults to ``True``.
    
        :param bool chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
        """
        parsed_url = parse_url(url)
        destination_scheme = parsed_url.scheme
    
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = preload_content
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = to_str(_encode_target(url))
        else:
            url = to_str(parsed_url.url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        http_tunnel_required = connection_requires_http_tunnel(
            self.proxy, self.proxy_config, destination_scheme
        )
    
        # Merge the proxy headers. Only done when not using HTTP CONNECT. We
        # have to copy the headers dict so we can safely change it without those
        # changes being reflected in anyone else's copy.
        if not http_tunnel_required:
            headers = headers.copy()  # type: ignore[attr-defined]
            headers.update(self.proxy_headers)  # type: ignore[union-attr]
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]
    
            # Is this a closed/new connection that requires CONNECT tunnelling?
            if self.proxy is not None and http_tunnel_required and conn.is_closed:
                try:
                    self._prepare_proxy(conn)
                except (BaseSSLError, OSError, SocketTimeout) as e:
                    self._raise_timeout(
                        err=e, url=self.proxy.url, timeout_value=conn.timeout
                    )
                    raise
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Make the request on the HTTPConnection object
>           response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
                retries=retries,
                response_conn=response_conn,
                preload_content=preload_content,
                decode_content=decode_content,
                **response_kw,
            )

.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:493: in _make_request
    conn.request(
.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:500: in request
    self.endheaders()
/usr/local/lib/python3.13/http/client.py:1353: in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
/usr/local/lib/python3.13/http/client.py:1113: in _send_output
    self.send(msg)
/usr/local/lib/python3.13/http/client.py:1057: in send
    self.connect()
.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:331: in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <HTTPConnection(host='localhost', port=8080) at 0x756a63359150>

    def _new_conn(self) -> socket.socket:
        """Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        try:
            sock = connection.create_connection(
                (self._dns_host, self.port),
                self.timeout,
                source_address=self.source_address,
                socket_options=self.socket_options,
            )
        except socket.gaierror as e:
            raise NameResolutionError(self.host, self, e) from e
        except SocketTimeout as e:
            raise ConnectTimeoutError(
                self,
                f"Connection to {self.host} timed out. (connect timeout={self.timeout})",
            ) from e
    
        except OSError as e:
>           raise NewConnectionError(
                self, f"Failed to establish a new connection: {e}"
            ) from e
E           urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused

.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:219: NewConnectionError

The above exception was the direct cause of the following exception:

self = <requests.adapters.HTTPAdapter object at 0x756a636808c0>
request = <PreparedRequest [GET]>, stream = False
timeout = Timeout(connect=120, read=120, total=None), verify = True, cert = None
proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )
    
        chunked = not (request.body is None or "Content-Length" in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, "
                    f"or a single float to set both timeouts to the same value."
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
>           resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )

.tbench-testing/lib/python3.13/site-packages/requests/adapters.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:841: in urlopen
    retries = retries.increment(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=0, read=7, redirect=7, status=7), method = 'GET'
url = '/api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100'
response = None
error = NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x756a63ffb4d0>
_stacktrace = <traceback object at 0x756a635c6f80>

    def increment(
        self,
        method: str | None = None,
        url: str | None = None,
        response: BaseHTTPResponse | None = None,
        error: Exception | None = None,
        _pool: ConnectionPool | None = None,
        _stacktrace: TracebackType | None = None,
    ) -> Self:
        """Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.BaseHTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        other = self.other
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or method is None or not self._is_method_retryable(method):
                raise reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif error:
            # Other retry?
            if other is not None:
                other -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            response_redirect_location = response.get_redirect_location()
            if response_redirect_location:
                redirect_location = response_redirect_location
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and the given method is in the allowed_methods
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            other=other,
            history=history,
        )
    
        if new_retry.is_exhausted():
            reason = error or ResponseError(cause)
>           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100 (Caused by NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused"))

.tbench-testing/lib/python3.13/site-packages/urllib3/util/retry.py:519: MaxRetryError

During handling of the above exception, another exception occurred:

host_creds = <mlflow.utils.rest_utils.MlflowHostCreds object at 0x756a63a4e3c0>
endpoint = '/api/2.0/mlflow/registered-models/search', method = 'GET'
max_retries = 7, backoff_factor = 2, backoff_jitter = 1.0, extra_headers = None
retry_codes = frozenset({408, 429, 500, 502, 503, 504}), timeout = 120
raise_on_status = True, respect_retry_after_header = True
retry_timeout_seconds = None
kwargs = {'params': {'filter': "tag.`mlflow.prompt.is_prompt` != 'true'", 'max_results': 100}}
cleaned_hostname = 'http://localhost:8080'
url = 'http://localhost:8080/api/2.0/mlflow/registered-models/search'

    def http_request(
        host_creds,
        endpoint,
        method,
        max_retries=None,
        backoff_factor=None,
        backoff_jitter=None,
        extra_headers=None,
        retry_codes=_TRANSIENT_FAILURE_RESPONSE_CODES,
        timeout=None,
        raise_on_status=True,
        respect_retry_after_header=None,
        retry_timeout_seconds=None,
        **kwargs,
    ):
        """Makes an HTTP request with the specified method to the specified hostname/endpoint. Transient
        errors such as Rate-limited (429), service unavailable (503) and internal error (500) are
        retried with an exponential back off with backoff_factor * (1, 2, 4, ... seconds).
        The function parses the API response (assumed to be JSON) into a Python object and returns it.
    
        Args:
            host_creds: A :py:class:`mlflow.rest_utils.MlflowHostCreds` object containing
                hostname and optional authentication.
            endpoint: A string for service endpoint, e.g. "/path/to/object".
            method: A string indicating the method to use, e.g. "GET", "POST", "PUT".
            max_retries: Maximum number of retries before throwing an exception.
            backoff_factor: A time factor for exponential backoff. e.g. value 5 means the HTTP
                request will be retried with interval 5, 10, 20... seconds. A value of 0 turns off the
                exponential backoff.
            backoff_jitter: A random jitter to add to the backoff interval.
            extra_headers: A dict of HTTP header name-value pairs to be included in the request.
            retry_codes: A list of HTTP response error codes that qualifies for retry.
            timeout: Wait for timeout seconds for response from remote server for connect and
                read request.
            raise_on_status: Whether to raise an exception, or return a response, if status falls
                in retry_codes range and retries have been exhausted.
            respect_retry_after_header: Whether to respect Retry-After header on status codes defined
                as Retry.RETRY_AFTER_STATUS_CODES or not.
            retry_timeout_seconds: Timeout for retires. Only effective when using Databricks SDK.
            kwargs: Additional keyword arguments to pass to `requests.Session.request()`
    
        Returns:
            requests.Response object.
        """
        cleaned_hostname = strip_suffix(host_creds.host, "/")
        url = f"{cleaned_hostname}{endpoint}"
    
        if host_creds.use_databricks_sdk:
            from databricks.sdk.errors import DatabricksError
    
            ws_client = get_workspace_client(
                host_creds.use_secret_scope_token,
                host_creds.host,
                host_creds.token,
                host_creds.databricks_auth_profile,
                retry_timeout_seconds=retry_timeout_seconds,
            )
            try:
                # Databricks SDK `APIClient.do` API is for making request using
                # HTTP
                # https://github.com/databricks/databricks-sdk-py/blob/a714146d9c155dd1e3567475be78623f72028ee0/databricks/sdk/core.py#L134
                raw_response = ws_client.api_client.do(
                    method=method,
                    path=endpoint,
                    headers=extra_headers,
                    raw=True,
                    query=kwargs.get("params"),
                    body=kwargs.get("json"),
                    files=kwargs.get("files"),
                    data=kwargs.get("data"),
                )
                return raw_response["contents"]._response
            except DatabricksError as e:
                response = requests.Response()
                response.url = url
                response.status_code = ERROR_CODE_TO_HTTP_STATUS.get(e.error_code, 500)
                response.reason = str(e)
                response.encoding = "UTF-8"
                response._content = json.dumps(
                    {
                        "error_code": e.error_code,
                        "message": str(e),
                    }
                ).encode("UTF-8")
    
                return response
    
        max_retries = MLFLOW_HTTP_REQUEST_MAX_RETRIES.get() if max_retries is None else max_retries
        backoff_factor = (
            MLFLOW_HTTP_REQUEST_BACKOFF_FACTOR.get() if backoff_factor is None else backoff_factor
        )
        _validate_max_retries(max_retries)
        _validate_backoff_factor(backoff_factor)
        respect_retry_after_header = (
            MLFLOW_HTTP_RESPECT_RETRY_AFTER_HEADER.get()
            if respect_retry_after_header is None
            else respect_retry_after_header
        )
        backoff_jitter = (
            MLFLOW_HTTP_REQUEST_BACKOFF_JITTER.get() if backoff_jitter is None else backoff_jitter
        )
    
        timeout = MLFLOW_HTTP_REQUEST_TIMEOUT.get() if timeout is None else timeout
        auth_str = None
        if host_creds.username and host_creds.password:
            basic_auth_str = f"{host_creds.username}:{host_creds.password}".encode()
            auth_str = "Basic " + base64.standard_b64encode(basic_auth_str).decode("utf-8")
        elif host_creds.token:
            auth_str = f"Bearer {host_creds.token}"
        elif host_creds.client_secret:
            raise MlflowException(
                "To use OAuth authentication, set environmental variable "
                f"'{MLFLOW_ENABLE_DB_SDK.name}' to true",
                error_code=CUSTOMER_UNAUTHORIZED,
            )
    
        from mlflow.tracking.request_header.registry import resolve_request_headers
    
        headers = dict(**resolve_request_headers())
        if extra_headers:
            headers = dict(**headers, **extra_headers)
    
        if auth_str:
            headers["Authorization"] = auth_str
    
        if host_creds.client_cert_path is not None:
            kwargs["cert"] = host_creds.client_cert_path
    
        if host_creds.aws_sigv4:
            # will overwrite the Authorization header
            from requests_auth_aws_sigv4 import AWSSigV4
    
            kwargs["auth"] = AWSSigV4("execute-api")
        elif host_creds.auth:
            from mlflow.tracking.request_auth.registry import fetch_auth
    
            kwargs["auth"] = fetch_auth(host_creds.auth)
    
        try:
>           return _get_http_response_with_retries(
                method,
                url,
                max_retries,
                backoff_factor,
                backoff_jitter,
                retry_codes,
                raise_on_status,
                headers=headers,
                verify=host_creds.verify,
                timeout=timeout,
                respect_retry_after_header=respect_retry_after_header,
                **kwargs,
            )

.tbench-testing/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/mlflow/utils/request_utils.py:237: in _get_http_response_with_retries
    return session.request(method, url, allow_redirects=allow_redirects, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/requests/sessions.py:589: in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/requests/sessions.py:703: in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x756a636808c0>
request = <PreparedRequest [GET]>, stream = False
timeout = Timeout(connect=120, read=120, total=None), verify = True, cert = None
proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )
    
        chunked = not (request.body is None or "Content-Length" in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, "
                    f"or a single float to set both timeouts to the same value."
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )
    
        except (ProtocolError, OSError) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100 (Caused by NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused"))

.tbench-testing/lib/python3.13/site-packages/requests/adapters.py:677: ConnectionError

During handling of the above exception, another exception occurred:

    def test_model_registered():
        """Ensure the model is registered."""
        mlflow.set_tracking_uri(uri="http://localhost:8080")
    
        client = mlflow.tracking.MlflowClient()
>       registered_models = client.search_registered_models()
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/mlflow/tracking/client.py:3829: in search_registered_models
    return self._get_registry_client().search_registered_models(
.tbench-testing/lib/python3.13/site-packages/mlflow/tracking/_model_registry/client.py:136: in search_registered_models
    return self.store.search_registered_models(filter_string, max_results, order_by, page_token)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/model_registry/rest_store.py:158: in search_registered_models
    response_proto = self._call_endpoint(SearchRegisteredModels, req_body)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/model_registry/base_rest_store.py:44: in _call_endpoint
    return call_endpoint(
.tbench-testing/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:397: in call_endpoint
    response = http_request(**call_kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

host_creds = <mlflow.utils.rest_utils.MlflowHostCreds object at 0x756a63a4e3c0>
endpoint = '/api/2.0/mlflow/registered-models/search', method = 'GET'
max_retries = 7, backoff_factor = 2, backoff_jitter = 1.0, extra_headers = None
retry_codes = frozenset({408, 429, 500, 502, 503, 504}), timeout = 120
raise_on_status = True, respect_retry_after_header = True
retry_timeout_seconds = None
kwargs = {'params': {'filter': "tag.`mlflow.prompt.is_prompt` != 'true'", 'max_results': 100}}
cleaned_hostname = 'http://localhost:8080'
url = 'http://localhost:8080/api/2.0/mlflow/registered-models/search'

    def http_request(
        host_creds,
        endpoint,
        method,
        max_retries=None,
        backoff_factor=None,
        backoff_jitter=None,
        extra_headers=None,
        retry_codes=_TRANSIENT_FAILURE_RESPONSE_CODES,
        timeout=None,
        raise_on_status=True,
        respect_retry_after_header=None,
        retry_timeout_seconds=None,
        **kwargs,
    ):
        """Makes an HTTP request with the specified method to the specified hostname/endpoint. Transient
        errors such as Rate-limited (429), service unavailable (503) and internal error (500) are
        retried with an exponential back off with backoff_factor * (1, 2, 4, ... seconds).
        The function parses the API response (assumed to be JSON) into a Python object and returns it.
    
        Args:
            host_creds: A :py:class:`mlflow.rest_utils.MlflowHostCreds` object containing
                hostname and optional authentication.
            endpoint: A string for service endpoint, e.g. "/path/to/object".
            method: A string indicating the method to use, e.g. "GET", "POST", "PUT".
            max_retries: Maximum number of retries before throwing an exception.
            backoff_factor: A time factor for exponential backoff. e.g. value 5 means the HTTP
                request will be retried with interval 5, 10, 20... seconds. A value of 0 turns off the
                exponential backoff.
            backoff_jitter: A random jitter to add to the backoff interval.
            extra_headers: A dict of HTTP header name-value pairs to be included in the request.
            retry_codes: A list of HTTP response error codes that qualifies for retry.
            timeout: Wait for timeout seconds for response from remote server for connect and
                read request.
            raise_on_status: Whether to raise an exception, or return a response, if status falls
                in retry_codes range and retries have been exhausted.
            respect_retry_after_header: Whether to respect Retry-After header on status codes defined
                as Retry.RETRY_AFTER_STATUS_CODES or not.
            retry_timeout_seconds: Timeout for retires. Only effective when using Databricks SDK.
            kwargs: Additional keyword arguments to pass to `requests.Session.request()`
    
        Returns:
            requests.Response object.
        """
        cleaned_hostname = strip_suffix(host_creds.host, "/")
        url = f"{cleaned_hostname}{endpoint}"
    
        if host_creds.use_databricks_sdk:
            from databricks.sdk.errors import DatabricksError
    
            ws_client = get_workspace_client(
                host_creds.use_secret_scope_token,
                host_creds.host,
                host_creds.token,
                host_creds.databricks_auth_profile,
                retry_timeout_seconds=retry_timeout_seconds,
            )
            try:
                # Databricks SDK `APIClient.do` API is for making request using
                # HTTP
                # https://github.com/databricks/databricks-sdk-py/blob/a714146d9c155dd1e3567475be78623f72028ee0/databricks/sdk/core.py#L134
                raw_response = ws_client.api_client.do(
                    method=method,
                    path=endpoint,
                    headers=extra_headers,
                    raw=True,
                    query=kwargs.get("params"),
                    body=kwargs.get("json"),
                    files=kwargs.get("files"),
                    data=kwargs.get("data"),
                )
                return raw_response["contents"]._response
            except DatabricksError as e:
                response = requests.Response()
                response.url = url
                response.status_code = ERROR_CODE_TO_HTTP_STATUS.get(e.error_code, 500)
                response.reason = str(e)
                response.encoding = "UTF-8"
                response._content = json.dumps(
                    {
                        "error_code": e.error_code,
                        "message": str(e),
                    }
                ).encode("UTF-8")
    
                return response
    
        max_retries = MLFLOW_HTTP_REQUEST_MAX_RETRIES.get() if max_retries is None else max_retries
        backoff_factor = (
            MLFLOW_HTTP_REQUEST_BACKOFF_FACTOR.get() if backoff_factor is None else backoff_factor
        )
        _validate_max_retries(max_retries)
        _validate_backoff_factor(backoff_factor)
        respect_retry_after_header = (
            MLFLOW_HTTP_RESPECT_RETRY_AFTER_HEADER.get()
            if respect_retry_after_header is None
            else respect_retry_after_header
        )
        backoff_jitter = (
            MLFLOW_HTTP_REQUEST_BACKOFF_JITTER.get() if backoff_jitter is None else backoff_jitter
        )
    
        timeout = MLFLOW_HTTP_REQUEST_TIMEOUT.get() if timeout is None else timeout
        auth_str = None
        if host_creds.username and host_creds.password:
            basic_auth_str = f"{host_creds.username}:{host_creds.password}".encode()
            auth_str = "Basic " + base64.standard_b64encode(basic_auth_str).decode("utf-8")
        elif host_creds.token:
            auth_str = f"Bearer {host_creds.token}"
        elif host_creds.client_secret:
            raise MlflowException(
                "To use OAuth authentication, set environmental variable "
                f"'{MLFLOW_ENABLE_DB_SDK.name}' to true",
                error_code=CUSTOMER_UNAUTHORIZED,
            )
    
        from mlflow.tracking.request_header.registry import resolve_request_headers
    
        headers = dict(**resolve_request_headers())
        if extra_headers:
            headers = dict(**headers, **extra_headers)
    
        if auth_str:
            headers["Authorization"] = auth_str
    
        if host_creds.client_cert_path is not None:
            kwargs["cert"] = host_creds.client_cert_path
    
        if host_creds.aws_sigv4:
            # will overwrite the Authorization header
            from requests_auth_aws_sigv4 import AWSSigV4
    
            kwargs["auth"] = AWSSigV4("execute-api")
        elif host_creds.auth:
            from mlflow.tracking.request_auth.registry import fetch_auth
    
            kwargs["auth"] = fetch_auth(host_creds.auth)
    
        try:
            return _get_http_response_with_retries(
                method,
                url,
                max_retries,
                backoff_factor,
                backoff_jitter,
                retry_codes,
                raise_on_status,
                headers=headers,
                verify=host_creds.verify,
                timeout=timeout,
                respect_retry_after_header=respect_retry_after_header,
                **kwargs,
            )
        except requests.exceptions.Timeout as to:
            raise MlflowException(
                f"API request to {url} failed with timeout exception {to}."
                " To increase the timeout, set the environment variable "
                f"{MLFLOW_HTTP_REQUEST_TIMEOUT!s} to a larger value."
            ) from to
        except requests.exceptions.InvalidURL as iu:
            raise InvalidUrlException(f"Invalid url: {url}") from iu
        except Exception as e:
>           raise MlflowException(f"API request to {url} failed with exception {e}")
E           mlflow.exceptions.MlflowException: API request to http://localhost:8080/api/2.0/mlflow/registered-models/search failed with exception HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100 (Caused by NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused"))

.tbench-testing/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:207: MlflowException
------------------------------ Captured log call -------------------------------
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=6, connect=6, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=5, connect=5, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=4, connect=4, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=3, connect=3, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=2, connect=2, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=1, connect=1, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=0, connect=0, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/search?filter=tag.%60mlflow.prompt.is_prompt%60+%21%3D+%27true%27&max_results=100
____________________________ test_model_dimensions _____________________________

self = <HTTPConnection(host='localhost', port=8080) at 0x756a6335b9b0>

    def _new_conn(self) -> socket.socket:
        """Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        try:
>           sock = connection.create_connection(
                (self._dns_host, self.port),
                self.timeout,
                source_address=self.source_address,
                socket_options=self.socket_options,
            )

.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:204: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/urllib3/util/connection.py:85: in create_connection
    raise err
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 8080), timeout = 120, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address: tuple[str, int],
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        source_address: tuple[str, int] | None = None,
        socket_options: _TYPE_SOCKET_OPTIONS | None = None,
    ) -> socket.socket:
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`socket.getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        try:
            host.encode("idna")
        except UnicodeError:
            raise LocationParseError(f"'{host}', label empty or too long") from None
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not _DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
>               sock.connect(sa)
E               ConnectionRefusedError: [Errno 111] Connection refused

.tbench-testing/lib/python3.13/site-packages/urllib3/util/connection.py:73: ConnectionRefusedError

The above exception was the direct cause of the following exception:

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x756a63ffb4d0>
method = 'POST', url = '/api/2.0/mlflow/registered-models/get-latest-versions'
body = b'{"name": "gpt-5"}'
headers = {'User-Agent': 'mlflow-python-client/2.22.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '17', 'Content-Type': 'application/json'}
retries = Retry(total=0, connect=0, read=7, redirect=7, status=7)
redirect = False, assert_same_host = False
timeout = Timeout(connect=120, read=120, total=None), pool_timeout = None
release_conn = False, chunked = False, body_pos = None, preload_content = False
decode_content = False, response_kw = {}
parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/api/2.0/mlflow/registered-models/get-latest-versions', query=None, fragment=None)
destination_scheme = None, conn = None, release_this_conn = True
http_tunnel_required = False, err = None, clean_exit = False

    def urlopen(  # type: ignore[override]
        self,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | bool | int | None = None,
        redirect: bool = True,
        assert_same_host: bool = True,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        pool_timeout: int | None = None,
        release_conn: bool | None = None,
        chunked: bool = False,
        body_pos: _TYPE_BODY_POSITION | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        **response_kw: typing.Any,
    ) -> BaseHTTPResponse:
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method
           such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param url:
            The URL to perform the request on.
    
        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param bool preload_content:
            If True, the response's body will be preloaded into memory.
    
        :param bool decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of ``preload_content``
            which defaults to ``True``.
    
        :param bool chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
        """
        parsed_url = parse_url(url)
        destination_scheme = parsed_url.scheme
    
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = preload_content
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = to_str(_encode_target(url))
        else:
            url = to_str(parsed_url.url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        http_tunnel_required = connection_requires_http_tunnel(
            self.proxy, self.proxy_config, destination_scheme
        )
    
        # Merge the proxy headers. Only done when not using HTTP CONNECT. We
        # have to copy the headers dict so we can safely change it without those
        # changes being reflected in anyone else's copy.
        if not http_tunnel_required:
            headers = headers.copy()  # type: ignore[attr-defined]
            headers.update(self.proxy_headers)  # type: ignore[union-attr]
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]
    
            # Is this a closed/new connection that requires CONNECT tunnelling?
            if self.proxy is not None and http_tunnel_required and conn.is_closed:
                try:
                    self._prepare_proxy(conn)
                except (BaseSSLError, OSError, SocketTimeout) as e:
                    self._raise_timeout(
                        err=e, url=self.proxy.url, timeout_value=conn.timeout
                    )
                    raise
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Make the request on the HTTPConnection object
>           response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
                retries=retries,
                response_conn=response_conn,
                preload_content=preload_content,
                decode_content=decode_content,
                **response_kw,
            )

.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:493: in _make_request
    conn.request(
.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:500: in request
    self.endheaders()
/usr/local/lib/python3.13/http/client.py:1353: in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
/usr/local/lib/python3.13/http/client.py:1113: in _send_output
    self.send(msg)
/usr/local/lib/python3.13/http/client.py:1057: in send
    self.connect()
.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:331: in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <HTTPConnection(host='localhost', port=8080) at 0x756a6335b9b0>

    def _new_conn(self) -> socket.socket:
        """Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        try:
            sock = connection.create_connection(
                (self._dns_host, self.port),
                self.timeout,
                source_address=self.source_address,
                socket_options=self.socket_options,
            )
        except socket.gaierror as e:
            raise NameResolutionError(self.host, self, e) from e
        except SocketTimeout as e:
            raise ConnectTimeoutError(
                self,
                f"Connection to {self.host} timed out. (connect timeout={self.timeout})",
            ) from e
    
        except OSError as e:
>           raise NewConnectionError(
                self, f"Failed to establish a new connection: {e}"
            ) from e
E           urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused

.tbench-testing/lib/python3.13/site-packages/urllib3/connection.py:219: NewConnectionError

The above exception was the direct cause of the following exception:

self = <requests.adapters.HTTPAdapter object at 0x756a636808c0>
request = <PreparedRequest [POST]>, stream = False
timeout = Timeout(connect=120, read=120, total=None), verify = True, cert = None
proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )
    
        chunked = not (request.body is None or "Content-Length" in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, "
                    f"or a single float to set both timeouts to the same value."
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
>           resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )

.tbench-testing/lib/python3.13/site-packages/requests/adapters.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:871: in urlopen
    return self.urlopen(
.tbench-testing/lib/python3.13/site-packages/urllib3/connectionpool.py:841: in urlopen
    retries = retries.increment(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=0, read=7, redirect=7, status=7), method = 'POST'
url = '/api/2.0/mlflow/registered-models/get-latest-versions', response = None
error = NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x756a63ffb4d0>
_stacktrace = <traceback object at 0x756a633bc500>

    def increment(
        self,
        method: str | None = None,
        url: str | None = None,
        response: BaseHTTPResponse | None = None,
        error: Exception | None = None,
        _pool: ConnectionPool | None = None,
        _stacktrace: TracebackType | None = None,
    ) -> Self:
        """Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.BaseHTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        other = self.other
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or method is None or not self._is_method_retryable(method):
                raise reraise(type(error), error, _stacktrace)
            elif read is not None:
                read -= 1
    
        elif error:
            # Other retry?
            if other is not None:
                other -= 1
    
        elif response and response.get_redirect_location():
            # Redirect retry?
            if redirect is not None:
                redirect -= 1
            cause = "too many redirects"
            response_redirect_location = response.get_redirect_location()
            if response_redirect_location:
                redirect_location = response_redirect_location
            status = response.status
    
        else:
            # Incrementing because of a server error like a 500 in
            # status_forcelist and the given method is in the allowed_methods
            cause = ResponseError.GENERIC_ERROR
            if response and response.status:
                if status_count is not None:
                    status_count -= 1
                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)
                status = response.status
    
        history = self.history + (
            RequestHistory(method, url, error, status, redirect_location),
        )
    
        new_retry = self.new(
            total=total,
            connect=connect,
            read=read,
            redirect=redirect,
            status=status_count,
            other=other,
            history=history,
        )
    
        if new_retry.is_exhausted():
            reason = error or ResponseError(cause)
>           raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/registered-models/get-latest-versions (Caused by NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused"))

.tbench-testing/lib/python3.13/site-packages/urllib3/util/retry.py:519: MaxRetryError

During handling of the above exception, another exception occurred:

host_creds = <mlflow.utils.rest_utils.MlflowHostCreds object at 0x756a63830690>
endpoint = '/api/2.0/mlflow/registered-models/get-latest-versions'
method = 'POST', max_retries = 7, backoff_factor = 2, backoff_jitter = 1.0
extra_headers = None, retry_codes = frozenset({408, 429, 500, 502, 503, 504})
timeout = 120, raise_on_status = True, respect_retry_after_header = True
retry_timeout_seconds = None, kwargs = {'json': {'name': 'gpt-5'}}
cleaned_hostname = 'http://localhost:8080'
url = 'http://localhost:8080/api/2.0/mlflow/registered-models/get-latest-versions'

    def http_request(
        host_creds,
        endpoint,
        method,
        max_retries=None,
        backoff_factor=None,
        backoff_jitter=None,
        extra_headers=None,
        retry_codes=_TRANSIENT_FAILURE_RESPONSE_CODES,
        timeout=None,
        raise_on_status=True,
        respect_retry_after_header=None,
        retry_timeout_seconds=None,
        **kwargs,
    ):
        """Makes an HTTP request with the specified method to the specified hostname/endpoint. Transient
        errors such as Rate-limited (429), service unavailable (503) and internal error (500) are
        retried with an exponential back off with backoff_factor * (1, 2, 4, ... seconds).
        The function parses the API response (assumed to be JSON) into a Python object and returns it.
    
        Args:
            host_creds: A :py:class:`mlflow.rest_utils.MlflowHostCreds` object containing
                hostname and optional authentication.
            endpoint: A string for service endpoint, e.g. "/path/to/object".
            method: A string indicating the method to use, e.g. "GET", "POST", "PUT".
            max_retries: Maximum number of retries before throwing an exception.
            backoff_factor: A time factor for exponential backoff. e.g. value 5 means the HTTP
                request will be retried with interval 5, 10, 20... seconds. A value of 0 turns off the
                exponential backoff.
            backoff_jitter: A random jitter to add to the backoff interval.
            extra_headers: A dict of HTTP header name-value pairs to be included in the request.
            retry_codes: A list of HTTP response error codes that qualifies for retry.
            timeout: Wait for timeout seconds for response from remote server for connect and
                read request.
            raise_on_status: Whether to raise an exception, or return a response, if status falls
                in retry_codes range and retries have been exhausted.
            respect_retry_after_header: Whether to respect Retry-After header on status codes defined
                as Retry.RETRY_AFTER_STATUS_CODES or not.
            retry_timeout_seconds: Timeout for retires. Only effective when using Databricks SDK.
            kwargs: Additional keyword arguments to pass to `requests.Session.request()`
    
        Returns:
            requests.Response object.
        """
        cleaned_hostname = strip_suffix(host_creds.host, "/")
        url = f"{cleaned_hostname}{endpoint}"
    
        if host_creds.use_databricks_sdk:
            from databricks.sdk.errors import DatabricksError
    
            ws_client = get_workspace_client(
                host_creds.use_secret_scope_token,
                host_creds.host,
                host_creds.token,
                host_creds.databricks_auth_profile,
                retry_timeout_seconds=retry_timeout_seconds,
            )
            try:
                # Databricks SDK `APIClient.do` API is for making request using
                # HTTP
                # https://github.com/databricks/databricks-sdk-py/blob/a714146d9c155dd1e3567475be78623f72028ee0/databricks/sdk/core.py#L134
                raw_response = ws_client.api_client.do(
                    method=method,
                    path=endpoint,
                    headers=extra_headers,
                    raw=True,
                    query=kwargs.get("params"),
                    body=kwargs.get("json"),
                    files=kwargs.get("files"),
                    data=kwargs.get("data"),
                )
                return raw_response["contents"]._response
            except DatabricksError as e:
                response = requests.Response()
                response.url = url
                response.status_code = ERROR_CODE_TO_HTTP_STATUS.get(e.error_code, 500)
                response.reason = str(e)
                response.encoding = "UTF-8"
                response._content = json.dumps(
                    {
                        "error_code": e.error_code,
                        "message": str(e),
                    }
                ).encode("UTF-8")
    
                return response
    
        max_retries = MLFLOW_HTTP_REQUEST_MAX_RETRIES.get() if max_retries is None else max_retries
        backoff_factor = (
            MLFLOW_HTTP_REQUEST_BACKOFF_FACTOR.get() if backoff_factor is None else backoff_factor
        )
        _validate_max_retries(max_retries)
        _validate_backoff_factor(backoff_factor)
        respect_retry_after_header = (
            MLFLOW_HTTP_RESPECT_RETRY_AFTER_HEADER.get()
            if respect_retry_after_header is None
            else respect_retry_after_header
        )
        backoff_jitter = (
            MLFLOW_HTTP_REQUEST_BACKOFF_JITTER.get() if backoff_jitter is None else backoff_jitter
        )
    
        timeout = MLFLOW_HTTP_REQUEST_TIMEOUT.get() if timeout is None else timeout
        auth_str = None
        if host_creds.username and host_creds.password:
            basic_auth_str = f"{host_creds.username}:{host_creds.password}".encode()
            auth_str = "Basic " + base64.standard_b64encode(basic_auth_str).decode("utf-8")
        elif host_creds.token:
            auth_str = f"Bearer {host_creds.token}"
        elif host_creds.client_secret:
            raise MlflowException(
                "To use OAuth authentication, set environmental variable "
                f"'{MLFLOW_ENABLE_DB_SDK.name}' to true",
                error_code=CUSTOMER_UNAUTHORIZED,
            )
    
        from mlflow.tracking.request_header.registry import resolve_request_headers
    
        headers = dict(**resolve_request_headers())
        if extra_headers:
            headers = dict(**headers, **extra_headers)
    
        if auth_str:
            headers["Authorization"] = auth_str
    
        if host_creds.client_cert_path is not None:
            kwargs["cert"] = host_creds.client_cert_path
    
        if host_creds.aws_sigv4:
            # will overwrite the Authorization header
            from requests_auth_aws_sigv4 import AWSSigV4
    
            kwargs["auth"] = AWSSigV4("execute-api")
        elif host_creds.auth:
            from mlflow.tracking.request_auth.registry import fetch_auth
    
            kwargs["auth"] = fetch_auth(host_creds.auth)
    
        try:
>           return _get_http_response_with_retries(
                method,
                url,
                max_retries,
                backoff_factor,
                backoff_jitter,
                retry_codes,
                raise_on_status,
                headers=headers,
                verify=host_creds.verify,
                timeout=timeout,
                respect_retry_after_header=respect_retry_after_header,
                **kwargs,
            )

.tbench-testing/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/mlflow/utils/request_utils.py:237: in _get_http_response_with_retries
    return session.request(method, url, allow_redirects=allow_redirects, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/requests/sessions.py:589: in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/requests/sessions.py:703: in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x756a636808c0>
request = <PreparedRequest [POST]>, stream = False
timeout = Timeout(connect=120, read=120, total=None), verify = True, cert = None
proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )
    
        chunked = not (request.body is None or "Content-Length" in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, "
                    f"or a single float to set both timeouts to the same value."
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )
    
        except (ProtocolError, OSError) as err:
            raise ConnectionError(err, request=request)
    
        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)
    
            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)
    
            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)
    
            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)
    
>           raise ConnectionError(e, request=request)
E           requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/registered-models/get-latest-versions (Caused by NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused"))

.tbench-testing/lib/python3.13/site-packages/requests/adapters.py:677: ConnectionError

During handling of the above exception, another exception occurred:

    def test_model_dimensions():
        mlflow.set_tracking_uri(uri="http://localhost:8080")
    
        model_name = "gpt-5"
        model_version = "latest"
    
>       model = mlflow.sklearn.load_model(f"models:/{model_name}/{model_version}")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tbench-testing/lib/python3.13/site-packages/mlflow/sklearn/__init__.py:633: in load_model
    local_model_path = _download_artifact_from_uri(artifact_uri=model_uri, output_path=dst_path)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/tracking/artifact_utils.py:108: in _download_artifact_from_uri
    repo = get_artifact_repository(artifact_uri=root_uri)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/artifact/artifact_repository_registry.py:133: in get_artifact_repository
    return _artifact_repository_registry.get_artifact_repository(artifact_uri)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/artifact/artifact_repository_registry.py:77: in get_artifact_repository
    return repository(artifact_uri)
           ^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/artifact/models_artifact_repo.py:69: in __init__
    ) = ModelsArtifactRepository._get_model_uri_infos(artifact_uri)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/artifact/models_artifact_repo.py:112: in _get_model_uri_infos
    name, version = get_model_name_and_version(client, uri)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/artifact/utils/models.py:99: in get_model_name_and_version
    return model_name, str(_get_latest_model_version(client, model_name, model_stage))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/artifact/utils/models.py:31: in _get_latest_model_version
    latest = client.get_latest_versions(name, None if stage is None else [stage])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/tracking/_model_registry/client.py:161: in get_latest_versions
    return self.store.get_latest_versions(name, stages)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/model_registry/rest_store.py:193: in get_latest_versions
    response_proto = self._call_endpoint(GetLatestVersions, req_body, call_all_endpoints=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
.tbench-testing/lib/python3.13/site-packages/mlflow/store/model_registry/base_rest_store.py:39: in _call_endpoint
    return call_endpoints(
.tbench-testing/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:415: in call_endpoints
    return call_endpoint(
.tbench-testing/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:400: in call_endpoint
    response = http_request(**call_kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

host_creds = <mlflow.utils.rest_utils.MlflowHostCreds object at 0x756a63830690>
endpoint = '/api/2.0/mlflow/registered-models/get-latest-versions'
method = 'POST', max_retries = 7, backoff_factor = 2, backoff_jitter = 1.0
extra_headers = None, retry_codes = frozenset({408, 429, 500, 502, 503, 504})
timeout = 120, raise_on_status = True, respect_retry_after_header = True
retry_timeout_seconds = None, kwargs = {'json': {'name': 'gpt-5'}}
cleaned_hostname = 'http://localhost:8080'
url = 'http://localhost:8080/api/2.0/mlflow/registered-models/get-latest-versions'

    def http_request(
        host_creds,
        endpoint,
        method,
        max_retries=None,
        backoff_factor=None,
        backoff_jitter=None,
        extra_headers=None,
        retry_codes=_TRANSIENT_FAILURE_RESPONSE_CODES,
        timeout=None,
        raise_on_status=True,
        respect_retry_after_header=None,
        retry_timeout_seconds=None,
        **kwargs,
    ):
        """Makes an HTTP request with the specified method to the specified hostname/endpoint. Transient
        errors such as Rate-limited (429), service unavailable (503) and internal error (500) are
        retried with an exponential back off with backoff_factor * (1, 2, 4, ... seconds).
        The function parses the API response (assumed to be JSON) into a Python object and returns it.
    
        Args:
            host_creds: A :py:class:`mlflow.rest_utils.MlflowHostCreds` object containing
                hostname and optional authentication.
            endpoint: A string for service endpoint, e.g. "/path/to/object".
            method: A string indicating the method to use, e.g. "GET", "POST", "PUT".
            max_retries: Maximum number of retries before throwing an exception.
            backoff_factor: A time factor for exponential backoff. e.g. value 5 means the HTTP
                request will be retried with interval 5, 10, 20... seconds. A value of 0 turns off the
                exponential backoff.
            backoff_jitter: A random jitter to add to the backoff interval.
            extra_headers: A dict of HTTP header name-value pairs to be included in the request.
            retry_codes: A list of HTTP response error codes that qualifies for retry.
            timeout: Wait for timeout seconds for response from remote server for connect and
                read request.
            raise_on_status: Whether to raise an exception, or return a response, if status falls
                in retry_codes range and retries have been exhausted.
            respect_retry_after_header: Whether to respect Retry-After header on status codes defined
                as Retry.RETRY_AFTER_STATUS_CODES or not.
            retry_timeout_seconds: Timeout for retires. Only effective when using Databricks SDK.
            kwargs: Additional keyword arguments to pass to `requests.Session.request()`
    
        Returns:
            requests.Response object.
        """
        cleaned_hostname = strip_suffix(host_creds.host, "/")
        url = f"{cleaned_hostname}{endpoint}"
    
        if host_creds.use_databricks_sdk:
            from databricks.sdk.errors import DatabricksError
    
            ws_client = get_workspace_client(
                host_creds.use_secret_scope_token,
                host_creds.host,
                host_creds.token,
                host_creds.databricks_auth_profile,
                retry_timeout_seconds=retry_timeout_seconds,
            )
            try:
                # Databricks SDK `APIClient.do` API is for making request using
                # HTTP
                # https://github.com/databricks/databricks-sdk-py/blob/a714146d9c155dd1e3567475be78623f72028ee0/databricks/sdk/core.py#L134
                raw_response = ws_client.api_client.do(
                    method=method,
                    path=endpoint,
                    headers=extra_headers,
                    raw=True,
                    query=kwargs.get("params"),
                    body=kwargs.get("json"),
                    files=kwargs.get("files"),
                    data=kwargs.get("data"),
                )
                return raw_response["contents"]._response
            except DatabricksError as e:
                response = requests.Response()
                response.url = url
                response.status_code = ERROR_CODE_TO_HTTP_STATUS.get(e.error_code, 500)
                response.reason = str(e)
                response.encoding = "UTF-8"
                response._content = json.dumps(
                    {
                        "error_code": e.error_code,
                        "message": str(e),
                    }
                ).encode("UTF-8")
    
                return response
    
        max_retries = MLFLOW_HTTP_REQUEST_MAX_RETRIES.get() if max_retries is None else max_retries
        backoff_factor = (
            MLFLOW_HTTP_REQUEST_BACKOFF_FACTOR.get() if backoff_factor is None else backoff_factor
        )
        _validate_max_retries(max_retries)
        _validate_backoff_factor(backoff_factor)
        respect_retry_after_header = (
            MLFLOW_HTTP_RESPECT_RETRY_AFTER_HEADER.get()
            if respect_retry_after_header is None
            else respect_retry_after_header
        )
        backoff_jitter = (
            MLFLOW_HTTP_REQUEST_BACKOFF_JITTER.get() if backoff_jitter is None else backoff_jitter
        )
    
        timeout = MLFLOW_HTTP_REQUEST_TIMEOUT.get() if timeout is None else timeout
        auth_str = None
        if host_creds.username and host_creds.password:
            basic_auth_str = f"{host_creds.username}:{host_creds.password}".encode()
            auth_str = "Basic " + base64.standard_b64encode(basic_auth_str).decode("utf-8")
        elif host_creds.token:
            auth_str = f"Bearer {host_creds.token}"
        elif host_creds.client_secret:
            raise MlflowException(
                "To use OAuth authentication, set environmental variable "
                f"'{MLFLOW_ENABLE_DB_SDK.name}' to true",
                error_code=CUSTOMER_UNAUTHORIZED,
            )
    
        from mlflow.tracking.request_header.registry import resolve_request_headers
    
        headers = dict(**resolve_request_headers())
        if extra_headers:
            headers = dict(**headers, **extra_headers)
    
        if auth_str:
            headers["Authorization"] = auth_str
    
        if host_creds.client_cert_path is not None:
            kwargs["cert"] = host_creds.client_cert_path
    
        if host_creds.aws_sigv4:
            # will overwrite the Authorization header
            from requests_auth_aws_sigv4 import AWSSigV4
    
            kwargs["auth"] = AWSSigV4("execute-api")
        elif host_creds.auth:
            from mlflow.tracking.request_auth.registry import fetch_auth
    
            kwargs["auth"] = fetch_auth(host_creds.auth)
    
        try:
            return _get_http_response_with_retries(
                method,
                url,
                max_retries,
                backoff_factor,
                backoff_jitter,
                retry_codes,
                raise_on_status,
                headers=headers,
                verify=host_creds.verify,
                timeout=timeout,
                respect_retry_after_header=respect_retry_after_header,
                **kwargs,
            )
        except requests.exceptions.Timeout as to:
            raise MlflowException(
                f"API request to {url} failed with timeout exception {to}."
                " To increase the timeout, set the environment variable "
                f"{MLFLOW_HTTP_REQUEST_TIMEOUT!s} to a larger value."
            ) from to
        except requests.exceptions.InvalidURL as iu:
            raise InvalidUrlException(f"Invalid url: {url}") from iu
        except Exception as e:
>           raise MlflowException(f"API request to {url} failed with exception {e}")
E           mlflow.exceptions.MlflowException: API request to http://localhost:8080/api/2.0/mlflow/registered-models/get-latest-versions failed with exception HTTPConnectionPool(host='localhost', port=8080): Max retries exceeded with url: /api/2.0/mlflow/registered-models/get-latest-versions (Caused by NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused"))

.tbench-testing/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:207: MlflowException
------------------------------ Captured log call -------------------------------
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=6, connect=6, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/get-latest-versions
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=5, connect=5, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/get-latest-versions
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=4, connect=4, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/get-latest-versions
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=3, connect=3, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/get-latest-versions
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=2, connect=2, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/get-latest-versions
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=1, connect=1, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/get-latest-versions
WARNING  urllib3.connectionpool:connectionpool.py:868 Retrying (Retry(total=0, connect=0, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError("HTTPConnection(host='localhost', port=8080): Failed to establish a new connection: [Errno 111] Connection refused")': /api/2.0/mlflow/registered-models/get-latest-versions
=============================== warnings summary ===============================
.tbench-testing/lib/python3.13/site-packages/mlflow/utils/pydantic_utils.py:33
  /app/.tbench-testing/lib/python3.13/site-packages/mlflow/utils/pydantic_utils.py:33: PydanticDeprecatedSince212: Using `@model_validator` with mode='after' on a classmethod is deprecated. Instead, use an instance method. See the documentation at https://docs.pydantic.dev/2.12/concepts/validators/#model-after-validator. Deprecated in Pydantic V2.12 to be removed in V3.0.
    return pydantic_model_validator(mode=mode)(func)

.tbench-testing/lib/python3.13/site-packages/mlflow/gateway/config.py:454
  /app/.tbench-testing/lib/python3.13/site-packages/mlflow/gateway/config.py:454: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/
    class Route(ConfigModel):

test_outputs.py::test_model_registered
  /app/.tbench-testing/lib/python3.13/site-packages/mlflow/store/model_registry/rest_store.py:150: DeprecationWarning: label() is deprecated. Use is_required() or is_repeated() instead.
    req_body = message_to_json(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../tests/test_outputs.py::test_mlflow_server_running - AssertionError:...
FAILED ../tests/test_outputs.py::test_model_registered - mlflow.exceptions.Ml...
FAILED ../tests/test_outputs.py::test_model_dimensions - mlflow.exceptions.Ml...
================== 3 failed, 3 warnings in 500.53s (0:08:20) ===================
